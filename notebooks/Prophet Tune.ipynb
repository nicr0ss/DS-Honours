{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96de3a4e-87c0-4e5f-a341-f3a77e79cfd1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T05:28:36.271280Z",
     "iopub.status.busy": "2025-03-06T05:28:36.270943Z",
     "iopub.status.idle": "2025-03-06T05:28:39.035635Z",
     "shell.execute_reply": "2025-03-06T05:28:39.035208Z",
     "shell.execute_reply.started": "2025-03-06T05:28:36.271262Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import ipyparallel as ipp\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import time\n",
    "from sklearn.model_selection import KFold\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import logging\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.ERROR)\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8f8be1cf-9efa-4fe5-affa-65d111c5fae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T05:38:45.038351Z",
     "iopub.status.busy": "2025-03-06T05:38:45.038101Z",
     "iopub.status.idle": "2025-03-06T05:41:42.193557Z",
     "shell.execute_reply": "2025-03-06T05:41:42.193019Z",
     "shell.execute_reply.started": "2025-03-06T05:38:45.038335Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing requests on engine(s)\n",
      "importing defaultdict from collections on engine(s)\n"
     ]
    }
   ],
   "source": [
    "def fetch_counts_for_year(year):\n",
    "    counts_for_year = defaultdict(int)\n",
    "    offset = 0\n",
    "    limit = 10000\n",
    "    while True:\n",
    "        url = (\n",
    "            f\"https://data.cnra.ca.gov/api/3/action/datastore_search?\"\n",
    "            f\"resource_id=bfa9f262-24a1-45bd-8dc8-138bc8107266\"\n",
    "            f\"&q={year}&limit={limit}&offset={offset}\"\n",
    "        )\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            records = data['result']['records']\n",
    "            for record in records:\n",
    "                site_code = record.get('site_code')\n",
    "                if record.get('gse_gwe') is None:\n",
    "                    continue\n",
    "                if site_code:\n",
    "                    counts_for_year[site_code] += 1\n",
    "            if len(records) < limit:\n",
    "                break\n",
    "            offset += limit\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for year {year}\")\n",
    "            break\n",
    "    return counts_for_year\n",
    "\n",
    "rc = ipp.Client()\n",
    "dview = rc[:]\n",
    "\n",
    "with dview.sync_imports():\n",
    "    import requests\n",
    "    from collections import defaultdict\n",
    "\n",
    "dview.push({'fetch_counts_for_year': fetch_counts_for_year})\n",
    "\n",
    "years = list(range(2000, 2025))\n",
    "\n",
    "async_results = dview.map_async(fetch_counts_for_year, years)\n",
    "results = async_results.get()\n",
    "\n",
    "counts = defaultdict(lambda: defaultdict(int))\n",
    "for year, year_counts in zip(years, results):\n",
    "    for site_code, count in year_counts.items():\n",
    "        counts[site_code][year] = count\n",
    "\n",
    "obs_df = pd.DataFrame.from_dict(counts, orient='index')\n",
    "obs_df = obs_df.fillna(0).astype(int)\n",
    "obs_df.columns = [f'observations_{year}' for year in obs_df.columns]\n",
    "obs_df = obs_df.reset_index().rename(columns={'index': 'site_code'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61769f60-b3c6-4378-951a-0ebec58afd3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T05:41:46.479948Z",
     "iopub.status.busy": "2025-03-06T05:41:46.479701Z",
     "iopub.status.idle": "2025-03-06T05:41:46.484410Z",
     "shell.execute_reply": "2025-03-06T05:41:46.484065Z",
     "shell.execute_reply.started": "2025-03-06T05:41:46.479933Z"
    }
   },
   "outputs": [],
   "source": [
    "columns_to_keep = ['site_code'] + [\n",
    "    col for col in obs_df.columns \n",
    "    if col.startswith('observations_') and int(col.split('_')[1]) >= 2008\n",
    "]\n",
    "\n",
    "ov25 = obs_df[columns_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f86e0571-b44d-49e9-a85a-b7b595e98394",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T05:41:48.017774Z",
     "iopub.status.busy": "2025-03-06T05:41:48.017561Z",
     "iopub.status.idle": "2025-03-06T05:41:48.023128Z",
     "shell.execute_reply": "2025-03-06T05:41:48.022755Z",
     "shell.execute_reply.started": "2025-03-06T05:41:48.017760Z"
    }
   },
   "outputs": [],
   "source": [
    "observation_columns = [col for col in ov25.columns if col.startswith('observations_')]\n",
    "ov25 = ov25[ov25[observation_columns].ge(25).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c32f2e56-cc7e-4430-9f8d-b78ac0a26776",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T05:41:59.514625Z",
     "iopub.status.busy": "2025-03-06T05:41:59.514340Z",
     "iopub.status.idle": "2025-03-06T05:41:59.518884Z",
     "shell.execute_reply": "2025-03-06T05:41:59.518512Z",
     "shell.execute_reply.started": "2025-03-06T05:41:59.514610Z"
    }
   },
   "outputs": [],
   "source": [
    "def fetch_all_records(site_code, year):\n",
    "    all_records = []\n",
    "    offset = 0\n",
    "    limit = 1000\n",
    "    while True:\n",
    "        url = (\n",
    "            f\"https://data.cnra.ca.gov/api/3/action/datastore_search?\"\n",
    "            f\"resource_id=bfa9f262-24a1-45bd-8dc8-138bc8107266\"\n",
    "            f\"&q={site_code} {year}&limit={limit}&offset={offset}\"\n",
    "        )\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            records = data['result']['records']\n",
    "            all_records.extend(records)\n",
    "            if len(records) < limit:\n",
    "                break\n",
    "            offset += limit\n",
    "        else:\n",
    "            print(f\"Failed to fetch data for {site_code} in {year}\")\n",
    "            break\n",
    "    return all_records\n",
    "\n",
    "def get_readings_for_site(site_code, years):\n",
    "    all_readings = []\n",
    "    for year in years:\n",
    "        records = fetch_all_records(site_code, year)\n",
    "        for record in records:\n",
    "            reading = {\n",
    "                'site_code': record.get('site_code'),\n",
    "                'msmt_date': record.get('msmt_date'),\n",
    "                'wlm_rpe': record.get('wlm_rpe'),\n",
    "                'wlm_gse': record.get('wlm_gse'),\n",
    "                'gwe': record.get('gwe')\n",
    "            }\n",
    "            all_readings.append(reading)\n",
    "    return pd.DataFrame(all_readings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "250ea8ee-43ec-42ce-9452-d797b466251d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T05:42:03.197103Z",
     "iopub.status.busy": "2025-03-06T05:42:03.196861Z",
     "iopub.status.idle": "2025-03-06T05:43:50.911493Z",
     "shell.execute_reply": "2025-03-06T05:43:50.911016Z",
     "shell.execute_reply.started": "2025-03-06T05:42:03.197089Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading site data: 100%|██████████| 183/183 [01:47<00:00,  1.70it/s]\n"
     ]
    }
   ],
   "source": [
    "rc = ipp.Client(timeout=1200)\n",
    "dview = rc[:]\n",
    "\n",
    "dview.push({\n",
    "    'fetch_all_records': fetch_all_records,\n",
    "    'get_readings_for_site': get_readings_for_site\n",
    "})\n",
    "\n",
    "dview.execute(\"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import itertools\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "logging.getLogger(\"cmdstanpy\").setLevel(logging.ERROR)\n",
    "\"\"\")\n",
    "\n",
    "years = list(range(2008, 2025))\n",
    "site_codes = ov25['site_code'].unique()\n",
    "\n",
    "def load_site_data(site_code, years):\n",
    "    return get_readings_for_site(site_code, years)\n",
    "\n",
    "site_data = list(tqdm(\n",
    "    dview.imap(load_site_data, site_codes, [years]*len(site_codes)),\n",
    "    total=len(site_codes),\n",
    "    desc=\"Loading site data\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6d085d9-c675-4922-a955-af6c8def24df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T05:49:10.048661Z",
     "iopub.status.busy": "2025-03-06T05:49:10.048334Z",
     "iopub.status.idle": "2025-03-06T09:56:13.656487Z",
     "shell.execute_reply": "2025-03-06T09:56:13.655920Z",
     "shell.execute_reply.started": "2025-03-06T05:49:10.048636Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [06:56<00:00, 11.25s/it]\n",
      "100%|██████████| 37/37 [07:17<00:00, 11.82s/it]\n",
      "100%|██████████| 37/37 [06:36<00:00, 10.73s/it]\n",
      "100%|██████████| 37/37 [07:14<00:00, 11.73s/it]\n",
      "100%|██████████| 37/37 [07:03<00:00, 11.44s/it]\n",
      "100%|██████████| 37/37 [07:36<00:00, 12.33s/it]\n",
      "100%|██████████| 37/37 [08:00<00:00, 12.99s/it]\n",
      "100%|██████████| 37/37 [08:11<00:00, 13.29s/it]\n",
      "100%|██████████| 37/37 [08:08<00:00, 13.20s/it]\n",
      "100%|██████████| 37/37 [07:59<00:00, 12.96s/it]\n",
      "100%|██████████| 37/37 [07:53<00:00, 12.81s/it]\n",
      "100%|██████████| 37/37 [08:22<00:00, 13.58s/it]\n",
      "100%|██████████| 37/37 [08:35<00:00, 13.92s/it]\n",
      "100%|██████████| 37/37 [08:31<00:00, 13.81s/it]\n",
      "100%|██████████| 37/37 [08:30<00:00, 13.80s/it]\n",
      "100%|██████████| 37/37 [08:10<00:00, 13.26s/it]\n",
      "100%|██████████| 37/37 [08:34<00:00, 13.90s/it]\n",
      "100%|██████████| 37/37 [08:47<00:00, 14.25s/it]\n",
      "100%|██████████| 37/37 [08:40<00:00, 14.06s/it]\n",
      "100%|██████████| 37/37 [08:43<00:00, 14.15s/it]\n",
      "100%|██████████| 37/37 [08:13<00:00, 13.34s/it]\n",
      "100%|██████████| 37/37 [08:33<00:00, 13.87s/it]\n",
      "100%|██████████| 37/37 [08:45<00:00, 14.20s/it]\n",
      "100%|██████████| 37/37 [08:48<00:00, 14.28s/it]\n",
      "100%|██████████| 37/37 [08:48<00:00, 14.29s/it]\n",
      "100%|██████████| 37/37 [08:30<00:00, 13.79s/it]\n",
      "100%|██████████| 37/37 [08:47<00:00, 14.26s/it]\n",
      "100%|██████████| 37/37 [08:56<00:00, 14.51s/it]\n",
      "100%|██████████| 37/37 [08:52<00:00, 14.38s/it]\n",
      "100%|██████████| 37/37 [08:51<00:00, 14.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated Cross Validation Grid Search Results (averaged over sites):\n",
      "                      horizon       mse      rmse       mae      mape  \\\n",
      "0  49 days 14:43:09.417757729  0.011480  0.038250  0.012461  0.000292   \n",
      "1  49 days 14:43:09.417757729  0.011552  0.038475  0.012490  0.000293   \n",
      "2  49 days 14:43:09.417757729  0.011573  0.038459  0.012465  0.000292   \n",
      "3  49 days 14:43:09.417757729  0.011597  0.038505  0.012497  0.000293   \n",
      "4  49 days 14:43:09.417757729  0.011606  0.038543  0.012501  0.000293   \n",
      "5  49 days 14:43:09.417757729  0.011166  0.037792  0.011919  0.000275   \n",
      "6  49 days 14:43:09.417757729  0.011455  0.038307  0.011953  0.000276   \n",
      "7  49 days 14:43:09.417757729  0.011472  0.038326  0.011950  0.000276   \n",
      "8  49 days 14:43:09.417757729  0.011466  0.038317  0.011954  0.000276   \n",
      "9  49 days 14:43:09.417757729  0.011544  0.038420  0.011960  0.000277   \n",
      "10 49 days 14:43:09.417757729  0.011124  0.037749  0.011833  0.000273   \n",
      "11 49 days 14:43:09.417757729  0.011471  0.038371  0.011883  0.000274   \n",
      "12 49 days 14:43:09.417757729  0.011507  0.038454  0.011883  0.000274   \n",
      "13 49 days 14:43:09.417757729  0.011583  0.038504  0.011885  0.000274   \n",
      "14 49 days 14:43:09.417757729  0.011624  0.038540  0.011887  0.000274   \n",
      "15 49 days 14:43:09.417757729  0.011471  0.038590  0.012186  0.000282   \n",
      "16 49 days 14:43:09.417757729  0.011955  0.039388  0.012260  0.000284   \n",
      "17 49 days 14:43:09.417757729  0.012215  0.039715  0.012288  0.000284   \n",
      "18 49 days 14:43:09.417757729  0.011978  0.039497  0.012267  0.000284   \n",
      "19 49 days 14:43:09.417757729  0.012235  0.039730  0.012279  0.000284   \n",
      "20 49 days 14:43:09.417757729  0.011672  0.039196  0.012458  0.000288   \n",
      "21 49 days 14:43:09.417757729  0.012108  0.039871  0.012488  0.000289   \n",
      "22 49 days 14:43:09.417757729  0.012388  0.040172  0.012525  0.000290   \n",
      "23 49 days 14:43:09.417757729  0.012331  0.040083  0.012516  0.000289   \n",
      "24 49 days 14:43:09.417757729  0.012276  0.040021  0.012487  0.000289   \n",
      "25 49 days 14:43:09.417757729  0.012186  0.040699  0.013151  0.000303   \n",
      "26 49 days 14:43:09.417757729  0.012953  0.041695  0.013248  0.000306   \n",
      "27 49 days 14:43:09.417757729  0.013351  0.042001  0.013273  0.000307   \n",
      "28 49 days 14:43:09.417757729  0.013148  0.041912  0.013294  0.000307   \n",
      "29 49 days 14:43:09.417757729  0.013095  0.041818  0.013238  0.000307   \n",
      "\n",
      "       mdape     smape  coverage  mase  rmsse  changepoint_prior_scale  \\\n",
      "0   0.000112  0.000293  0.971522   NaN    NaN                    0.001   \n",
      "1   0.000112  0.000294  0.970781   NaN    NaN                    0.001   \n",
      "2   0.000111  0.000293  0.970952   NaN    NaN                    0.001   \n",
      "3   0.000112  0.000295  0.970493   NaN    NaN                    0.001   \n",
      "4   0.000112  0.000295  0.971148   NaN    NaN                    0.001   \n",
      "5   0.000089  0.000277  0.971554   NaN    NaN                    0.005   \n",
      "6   0.000088  0.000278  0.971133   NaN    NaN                    0.005   \n",
      "7   0.000088  0.000278  0.971215   NaN    NaN                    0.005   \n",
      "8   0.000088  0.000278  0.971577   NaN    NaN                    0.005   \n",
      "9   0.000088  0.000278  0.971620   NaN    NaN                    0.005   \n",
      "10  0.000086  0.000274  0.971837   NaN    NaN                    0.010   \n",
      "11  0.000085  0.000276  0.970997   NaN    NaN                    0.010   \n",
      "12  0.000085  0.000275  0.971313   NaN    NaN                    0.010   \n",
      "13  0.000085  0.000276  0.970947   NaN    NaN                    0.010   \n",
      "14  0.000085  0.000276  0.970809   NaN    NaN                    0.010   \n",
      "15  0.000088  0.000283  0.971524   NaN    NaN                    0.050   \n",
      "16  0.000088  0.000285  0.970336   NaN    NaN                    0.050   \n",
      "17  0.000088  0.000286  0.971003   NaN    NaN                    0.050   \n",
      "18  0.000088  0.000285  0.970449   NaN    NaN                    0.050   \n",
      "19  0.000088  0.000286  0.970954   NaN    NaN                    0.050   \n",
      "20  0.000090  0.000289  0.970684   NaN    NaN                    0.100   \n",
      "21  0.000089  0.000290  0.971926   NaN    NaN                    0.100   \n",
      "22  0.000089  0.000291  0.971913   NaN    NaN                    0.100   \n",
      "23  0.000089  0.000291  0.970976   NaN    NaN                    0.100   \n",
      "24  0.000089  0.000290  0.969373   NaN    NaN                    0.100   \n",
      "25  0.000091  0.000304  0.971017   NaN    NaN                    0.500   \n",
      "26  0.000090  0.000307  0.969809   NaN    NaN                    0.500   \n",
      "27  0.000090  0.000308  0.970145   NaN    NaN                    0.500   \n",
      "28  0.000090  0.000308  0.970413   NaN    NaN                    0.500   \n",
      "29  0.000090  0.000308  0.970323   NaN    NaN                    0.500   \n",
      "\n",
      "    seasonality_prior_scale seasonality_mode  n_sites  \n",
      "0                      0.01         additive      183  \n",
      "1                      0.10         additive      183  \n",
      "2                      0.50         additive      183  \n",
      "3                      1.00         additive      183  \n",
      "4                     10.00         additive      183  \n",
      "5                      0.01         additive      183  \n",
      "6                      0.10         additive      183  \n",
      "7                      0.50         additive      183  \n",
      "8                      1.00         additive      183  \n",
      "9                     10.00         additive      183  \n",
      "10                     0.01         additive      183  \n",
      "11                     0.10         additive      183  \n",
      "12                     0.50         additive      183  \n",
      "13                     1.00         additive      183  \n",
      "14                    10.00         additive      183  \n",
      "15                     0.01         additive      183  \n",
      "16                     0.10         additive      183  \n",
      "17                     0.50         additive      183  \n",
      "18                     1.00         additive      183  \n",
      "19                    10.00         additive      183  \n",
      "20                     0.01         additive      183  \n",
      "21                     0.10         additive      183  \n",
      "22                     0.50         additive      183  \n",
      "23                     1.00         additive      183  \n",
      "24                    10.00         additive      183  \n",
      "25                     0.01         additive      183  \n",
      "26                     0.10         additive      183  \n",
      "27                     0.50         additive      183  \n",
      "28                     1.00         additive      183  \n",
      "29                    10.00         additive      183  \n",
      "\n",
      "Best Parameters based on aggregated MASE:\n",
      "horizon                    49 days 14:43:09.417757729\n",
      "mse                                           0.01148\n",
      "rmse                                          0.03825\n",
      "mae                                          0.012461\n",
      "mape                                         0.000292\n",
      "mdape                                        0.000112\n",
      "smape                                        0.000293\n",
      "coverage                                     0.971522\n",
      "mase                                              NaN\n",
      "rmsse                                             NaN\n",
      "changepoint_prior_scale                         0.001\n",
      "seasonality_prior_scale                          0.01\n",
      "seasonality_mode                             additive\n",
      "n_sites                                           183\n",
      "Name: 0, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_dict = dict(zip(site_codes, site_data))\n",
    "dview.push({'data_dict': data_dict})\n",
    "\n",
    "def process_site(site_code, years, cps, sps):\n",
    "    try:\n",
    "        df = data_dict.get(site_code)\n",
    "        if df is None or df.empty:\n",
    "            return None\n",
    "\n",
    "        df['msmt_date'] = pd.to_datetime(df['msmt_date'])\n",
    "        df = df[['msmt_date', 'wlm_rpe']].rename(columns={'msmt_date': 'ds', 'wlm_rpe': 'y'})\n",
    "        df = df.sort_values('ds')\n",
    "\n",
    "        model = Prophet(changepoint_prior_scale=cps,\n",
    "                        seasonality_prior_scale=sps,\n",
    "                        seasonality_mode='additive',\n",
    "                        yearly_seasonality=True)\n",
    "        model.fit(df)\n",
    "        \n",
    "        cv_results = cross_validation(model,\n",
    "                                      initial='730 days',\n",
    "                                      period='90 days',\n",
    "                                      horizon='90 days',\n",
    "                                      parallel=\"processes\")\n",
    "        metrics_df = performance_metrics(cv_results)\n",
    "        avg_metrics = metrics_df.mean()\n",
    "        \n",
    "        y_full = df['y'].values\n",
    "        scale_mase = np.mean(np.abs(np.diff(y_full)))\n",
    "        scale_rmsse = np.mean((np.diff(y_full))**2)\n",
    "        \n",
    "        mae_cv = np.mean(np.abs(cv_results['y'] - cv_results['yhat']))\n",
    "        mse_cv = np.mean((cv_results['y'] - cv_results['yhat'])**2)\n",
    "        \n",
    "        mase_val = mae_cv / scale_mase if scale_mase != 0 else np.nan\n",
    "        rmsse_val = np.sqrt(mse_cv / scale_rmsse) if scale_rmsse != 0 else np.nan\n",
    "        \n",
    "        avg_metrics_dict = avg_metrics.to_dict()\n",
    "        avg_metrics_dict['mase'] = mase_val\n",
    "        avg_metrics_dict['rmsse'] = rmsse_val\n",
    "        \n",
    "        return avg_metrics_dict\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "dview.push({'process_site': process_site})\n",
    "\n",
    "param_grid = {\n",
    "    'changepoint_prior_scale': [0.001, 0.005, 0.01, 0.05, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 0.5, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "CHUNK_SIZE = 5\n",
    "\n",
    "aggregated_results = []\n",
    "grid = list(itertools.product(param_grid['changepoint_prior_scale'],\n",
    "                              param_grid['seasonality_prior_scale']))\n",
    "\n",
    "for cps, sps in grid:\n",
    "    collected = {}\n",
    "    n_valid = 0\n",
    "    \n",
    "    for start_idx in tqdm(range(0, len(site_codes), CHUNK_SIZE)):\n",
    "        chunk = site_codes[start_idx : start_idx + CHUNK_SIZE]\n",
    "\n",
    "        async_results = dview.map_async(\n",
    "            process_site,\n",
    "            chunk,\n",
    "            [years] * len(chunk),\n",
    "            [cps]   * len(chunk),\n",
    "            [sps]   * len(chunk)\n",
    "        )\n",
    "\n",
    "        site_results = async_results.get()\n",
    "        for res in site_results:\n",
    "            if res is not None:\n",
    "                n_valid += 1\n",
    "                for key, value in res.items():\n",
    "                    collected.setdefault(key, []).append(value)\n",
    "\n",
    "    if n_valid > 0:\n",
    "        avg_metrics = {key: np.mean(vals) for key, vals in collected.items()}\n",
    "        avg_metrics.update({\n",
    "            'changepoint_prior_scale': cps,\n",
    "            'seasonality_prior_scale': sps,\n",
    "            'seasonality_mode': 'additive',\n",
    "            'n_sites': n_valid\n",
    "        })\n",
    "        aggregated_results.append(avg_metrics)\n",
    "    else:\n",
    "        print(f\"No valid results for parameters: cps={cps}, sps={sps}\")\n",
    "\n",
    "results_df = pd.DataFrame(aggregated_results)\n",
    "results_df = results_df.sort_values('mase')\n",
    "results_df.to_csv(\"prophet_train.csv\", index=False)\n",
    "\n",
    "print(\"Aggregated Cross Validation Grid Search Results (averaged over sites):\")\n",
    "print(results_df)\n",
    "print(\"\\nBest Parameters based on aggregated MASE:\")\n",
    "print(results_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83fb3d11-6e8b-4e7b-9932-86386fb84f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T09:56:33.350703Z",
     "iopub.status.busy": "2025-03-06T09:56:33.350569Z",
     "iopub.status.idle": "2025-03-06T09:56:33.556611Z",
     "shell.execute_reply": "2025-03-06T09:56:33.556060Z",
     "shell.execute_reply.started": "2025-03-06T09:56:33.350692Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 62\u001b[0m\n\u001b[1;32m     59\u001b[0m all_site_metrics \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m site_code \u001b[38;5;129;01min\u001b[39;00m ov25:\n\u001b[0;32m---> 62\u001b[0m     forecast, df \u001b[38;5;241m=\u001b[39m prophet_interpolation(site_code, best_cps, best_sps)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m forecast \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m df \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     64\u001b[0m         metrics \u001b[38;5;241m=\u001b[39m calculate_quarterly_error_metrics(forecast, df)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "best_params = results_df.iloc[0]\n",
    "best_cps = best_params['changepoint_prior_scale']\n",
    "best_sps = best_params['seasonality_prior_scale']\n",
    "\n",
    "def prophet_interpolation(site_code, cps, sps):\n",
    "    try:\n",
    "        df = data_dict.get(site_code)\n",
    "        if df is None or df.empty:\n",
    "            return None\n",
    "\n",
    "        df['msmt_date'] = pd.to_datetime(df['msmt_date'])\n",
    "        df = df[['msmt_date', 'wlm_rpe']].rename(columns={'msmt_date': 'ds', 'wlm_rpe': 'y'})\n",
    "        df = df.sort_values('ds')\n",
    "\n",
    "        model = Prophet(changepoint_prior_scale=cps,\n",
    "                        seasonality_prior_scale=sps,\n",
    "                        seasonality_mode='additive',\n",
    "                        yearly_seasonality=True)\n",
    "        model.fit(df)\n",
    "        \n",
    "        future = model.make_future_dataframe(periods=365)  # Adjust periods as needed\n",
    "        forecast = model.predict(future)\n",
    "        \n",
    "        return forecast, df\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing site {site_code}: {e}\")\n",
    "        return None, None\n",
    "\n",
    "def calculate_quarterly_error_metrics(forecast, df):\n",
    "    # Merge forecast with actual data\n",
    "    merged = pd.merge(df, forecast[['ds', 'yhat']], on='ds', how='inner')\n",
    "    \n",
    "    # Extract quarter from the date\n",
    "    merged['quarter'] = merged['ds'].dt.quarter  # 1=Q1, 2=Q2, 3=Q3, 4=Q4\n",
    "    \n",
    "    # Initialize a dictionary to store quarterly metrics\n",
    "    quarterly_metrics = {}\n",
    "    \n",
    "    for quarter in range(1, 5):\n",
    "        quarter_data = merged[merged['quarter'] == quarter]\n",
    "        \n",
    "        if len(quarter_data) > 0:\n",
    "            # Calculate error metrics for the quarter\n",
    "            mae = np.mean(np.abs(quarter_data['y'] - quarter_data['yhat']))\n",
    "            mse = np.mean((quarter_data['y'] - quarter_data['yhat'])**2)\n",
    "            rmse = np.sqrt(mse)\n",
    "            \n",
    "            quarterly_metrics[f'q{quarter}_mae'] = mae\n",
    "            quarterly_metrics[f'q{quarter}_mse'] = mse\n",
    "            quarterly_metrics[f'q{quarter}_rmse'] = rmse\n",
    "        else:\n",
    "            # If no data for the quarter, set metrics to NaN\n",
    "            quarterly_metrics[f'q{quarter}_mae'] = np.nan\n",
    "            quarterly_metrics[f'q{quarter}_mse'] = np.nan\n",
    "            quarterly_metrics[f'q{quarter}_rmse'] = np.nan\n",
    "    \n",
    "    return quarterly_metrics\n",
    "\n",
    "all_site_metrics = []\n",
    "\n",
    "for site_code in ov25:\n",
    "    forecast, df = prophet_interpolation(site_code, best_cps, best_sps)\n",
    "    if forecast is not None and df is not None:\n",
    "        metrics = calculate_quarterly_error_metrics(forecast, df)\n",
    "        metrics['site_code'] = site_code\n",
    "        all_site_metrics.append(metrics)\n",
    "\n",
    "# Convert to DataFrame for easier analysis\n",
    "metrics_df = pd.DataFrame(all_site_metrics)\n",
    "metrics_df.to_csv(\"prophet_interpolation_quarterly_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Quarterly Error Metrics for Each Site:\")\n",
    "print(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e86d1f-92eb-493a-b8f4-905e78fd52c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222d693-f02d-497a-9ea6-421931a39f65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
